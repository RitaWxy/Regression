{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data \n",
    "+ Pre-processing \n",
    "+ Feature-Extractor\n",
    "+ Split Training, Test, Validation\n",
    "+ Build Model\n",
    "+ Gradient Descent \n",
    "+ Evaluation\n",
    "+ Predicat\n",
    "+ Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = load_boston()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataframe['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入csv\n",
    "data = pd.DataFrame(dataframe['data'],columns=dataframe['feature_names'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 观察数据类别，哪些数据需要onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "501    0\n",
       "502    0\n",
       "503    0\n",
       "504    0\n",
       "505    0\n",
       "Name: CHAS, Length: 506, dtype: category\n",
       "Categories (2, int64): [0, 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CHAS'] = data['CHAS'].astype('int')\n",
    "data['CHAS'] = data['CHAS'].astype('category')\n",
    "data['CHAS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      2\n",
       "2      2\n",
       "3      3\n",
       "4      3\n",
       "      ..\n",
       "501    1\n",
       "502    1\n",
       "503    1\n",
       "504    1\n",
       "505    1\n",
       "Name: RAD, Length: 506, dtype: category\n",
       "Categories (9, int64): [1, 2, 3, 4, ..., 6, 7, 8, 24]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['RAD'] = data['RAD'].astype('int')\n",
    "data['RAD'] = data['RAD'].astype('category')\n",
    "data['RAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehoter = OneHotEncoder()\n",
    "chas_and_rad = onehoter.fit_transform(data[['CHAS','RAD']])\n",
    "chas_and_rad.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM         8.601545\n",
       "ZN          23.322453\n",
       "INDUS        6.860353\n",
       "CHAS         0.253994\n",
       "NOX          0.115878\n",
       "RM           0.702617\n",
       "AGE         28.148861\n",
       "DIS          2.105710\n",
       "RAD          8.707259\n",
       "TAX        168.537116\n",
       "PTRATIO      2.164946\n",
       "B           91.294864\n",
       "LSTAT        7.141062\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS    NOX     RM   AGE     DIS    TAX  PTRATIO       B  \\\n",
       "0    0.00632  18.0   2.31  0.538  6.575  65.2  4.0900  296.0     15.3  396.90   \n",
       "1    0.02731   0.0   7.07  0.469  6.421  78.9  4.9671  242.0     17.8  396.90   \n",
       "2    0.02729   0.0   7.07  0.469  7.185  61.1  4.9671  242.0     17.8  392.83   \n",
       "3    0.03237   0.0   2.18  0.458  6.998  45.8  6.0622  222.0     18.7  394.63   \n",
       "4    0.06905   0.0   2.18  0.458  7.147  54.2  6.0622  222.0     18.7  396.90   \n",
       "..       ...   ...    ...    ...    ...   ...     ...    ...      ...     ...   \n",
       "501  0.06263   0.0  11.93  0.573  6.593  69.1  2.4786  273.0     21.0  391.99   \n",
       "502  0.04527   0.0  11.93  0.573  6.120  76.7  2.2875  273.0     21.0  396.90   \n",
       "503  0.06076   0.0  11.93  0.573  6.976  91.0  2.1675  273.0     21.0  396.90   \n",
       "504  0.10959   0.0  11.93  0.573  6.794  89.3  2.3889  273.0     21.0  393.45   \n",
       "505  0.04741   0.0  11.93  0.573  6.030  80.8  2.5050  273.0     21.0  396.90   \n",
       "\n",
       "     LSTAT  \n",
       "0     4.98  \n",
       "1     9.14  \n",
       "2     4.03  \n",
       "3     2.94  \n",
       "4     5.33  \n",
       "..     ...  \n",
       "501   9.67  \n",
       "502   9.08  \n",
       "503   5.64  \n",
       "504   6.48  \n",
       "505   7.88  \n",
       "\n",
       "[506 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns = ['CHAS','RAD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ..., -1.45900038,\n",
       "         0.44105193, -1.0755623 ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.44105193, -0.49243937],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ..., -0.30309415,\n",
       "         0.39642699, -1.2087274 ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.98304761],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.4032249 , -0.86530163],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  1.17646583,\n",
       "         0.44105193, -0.66905833]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standar = StandardScaler()\n",
    "after_scale = standar.fit_transform(data.drop(columns = ['CHAS','RAD']))\n",
    "after_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化，均值接近0，标准差接近1的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12338772e-16,  7.89881994e-17,  2.10635198e-16, -1.96592852e-16,\n",
       "       -1.08828186e-16, -1.47444639e-16, -8.42540793e-17,  0.00000000e+00,\n",
       "       -4.21270397e-16, -7.44244367e-16, -3.08931624e-16])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(after_scale,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(after_scale,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41978194,  0.28482986, -1.2879095 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41733926, -0.48772236, -0.59338101, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41734159, -0.48772236, -0.59338101, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.41344658, -0.48772236,  0.11573841, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.40776407, -0.48772236,  0.11573841, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41500016, -0.48772236,  0.11573841, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并数据\n",
    "X = np.concatenate((after_scale,chas_and_rad.toarray()),axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "concatenate((a1, a2, ...), axis=0, out=None)\n",
       "\n",
       "Join a sequence of arrays along an existing axis.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a1, a2, ... : sequence of array_like\n",
       "    The arrays must have the same shape, except in the dimension\n",
       "    corresponding to `axis` (the first, by default).\n",
       "axis : int, optional\n",
       "    The axis along which the arrays will be joined.  If axis is None,\n",
       "    arrays are flattened before use.  Default is 0.\n",
       "out : ndarray, optional\n",
       "    If provided, the destination to place the result. The shape must be\n",
       "    correct, matching that of what concatenate would have returned if no\n",
       "    out argument were specified.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "res : ndarray\n",
       "    The concatenated array.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ma.concatenate : Concatenate function that preserves input masks.\n",
       "array_split : Split an array into multiple sub-arrays of equal or\n",
       "              near-equal size.\n",
       "split : Split array into a list of multiple sub-arrays of equal size.\n",
       "hsplit : Split array into multiple sub-arrays horizontally (column wise)\n",
       "vsplit : Split array into multiple sub-arrays vertically (row wise)\n",
       "dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n",
       "stack : Stack a sequence of arrays along a new axis.\n",
       "hstack : Stack arrays in sequence horizontally (column wise)\n",
       "vstack : Stack arrays in sequence vertically (row wise)\n",
       "dstack : Stack arrays in sequence depth wise (along third dimension)\n",
       "block : Assemble arrays from blocks.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "When one or more of the arrays to be concatenated is a MaskedArray,\n",
       "this function will return a MaskedArray object instead of an ndarray,\n",
       "but the input masks are *not* preserved. In cases where a MaskedArray\n",
       "is expected as input, use the ma.concatenate function from the masked\n",
       "array module instead.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.array([[1, 2], [3, 4]])\n",
       ">>> b = np.array([[5, 6]])\n",
       ">>> np.concatenate((a, b), axis=0)\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])\n",
       ">>> np.concatenate((a, b.T), axis=1)\n",
       "array([[1, 2, 5],\n",
       "       [3, 4, 6]])\n",
       ">>> np.concatenate((a, b), axis=None)\n",
       "array([1, 2, 3, 4, 5, 6])\n",
       "\n",
       "This function will not preserve masking of MaskedArray inputs.\n",
       "\n",
       ">>> a = np.ma.arange(3)\n",
       ">>> a[1] = np.ma.masked\n",
       ">>> b = np.arange(2, 5)\n",
       ">>> a\n",
       "masked_array(data=[0, --, 2],\n",
       "             mask=[False,  True, False],\n",
       "       fill_value=999999)\n",
       ">>> b\n",
       "array([2, 3, 4])\n",
       ">>> np.concatenate([a, b])\n",
       "masked_array(data=[0, 1, 2, 2, 3, 4],\n",
       "             mask=False,\n",
       "       fill_value=999999)\n",
       ">>> np.ma.concatenate([a, b])\n",
       "masked_array(data=[0, --, 2, 2, 3, 4],\n",
       "             mask=[False,  True, False, False, False, False],\n",
       "       fill_value=999999)\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??np.concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataframe['target']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 22)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdata(x,y,test_ratio = 0.2,val_ratio = 0.2):\n",
    "    '''\n",
    "    打乱数据：往往先生成重新打乱的下标序号index，根据序号取x&y\n",
    "    '''\n",
    "    indices = np.random.choice(range(len(X)),size = len(X),replace = False)\n",
    "    \n",
    "    train_indices = indices[:int(len(X)*(1-test_ratio)*(1-val_ratio))]\n",
    "    val_indices = indices[int(len(X)*(1-test_ratio)*(1-val_ratio)): int(len(X)*(1-test_ratio))]\n",
    "    test_indices = indices[int(len(X)*(1-test_ratio)):]\n",
    "    \n",
    "    return (x[train_indices], y[train_indices]), (x[val_indices], y[val_indices]), (x[test_indices], y[test_indices]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "choice(a, size=None, replace=True, p=None)\n",
       "\n",
       "Generates a random sample from a given 1-D array\n",
       "\n",
       "        .. versionadded:: 1.7.0\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : 1-D array-like or int\n",
       "    If an ndarray, a random sample is generated from its elements.\n",
       "    If an int, the random sample is generated as if a were np.arange(a)\n",
       "size : int or tuple of ints, optional\n",
       "    Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
       "    ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
       "    single value is returned.\n",
       "replace : boolean, optional\n",
       "    Whether the sample is with or without replacement\n",
       "p : 1-D array-like, optional\n",
       "    The probabilities associated with each entry in a.\n",
       "    If not given the sample assumes a uniform distribution over all\n",
       "    entries in a.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "samples : single item or ndarray\n",
       "    The generated random samples\n",
       "\n",
       "Raises\n",
       "------\n",
       "ValueError\n",
       "    If a is an int and less than zero, if a or p are not 1-dimensional,\n",
       "    if a is an array-like of size 0, if p is not a vector of\n",
       "    probabilities, if a and p have different lengths, or if\n",
       "    replace=False and the sample size is greater than the population\n",
       "    size\n",
       "\n",
       "See Also\n",
       "--------\n",
       "randint, shuffle, permutation\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Generate a uniform random sample from np.arange(5) of size 3:\n",
       "\n",
       ">>> np.random.choice(5, 3)\n",
       "array([0, 3, 4]) # random\n",
       ">>> #This is equivalent to np.random.randint(0,5,3)\n",
       "\n",
       "Generate a non-uniform random sample from np.arange(5) of size 3:\n",
       "\n",
       ">>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
       "array([3, 3, 0]) # random\n",
       "\n",
       "Generate a uniform random sample from np.arange(5) of size 3 without\n",
       "replacement:\n",
       "\n",
       ">>> np.random.choice(5, 3, replace=False)\n",
       "array([3,1,0]) # random\n",
       ">>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
       "\n",
       "Generate a non-uniform random sample from np.arange(5) of size\n",
       "3 without replacement:\n",
       "\n",
       ">>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
       "array([2, 3, 0]) # random\n",
       "\n",
       "Any of the above can be repeated with an arbitrary array-like\n",
       "instead of just integers. For instance:\n",
       "\n",
       ">>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
       ">>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
       "array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
       "      dtype='<U11')\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??np.random.choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = splitdata(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn.model_selection.train_test_split 也可以实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65387518, -0.48772236,  1.01599907, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.34935053,  0.370669  , -1.04569998, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.41393069, -0.48772236, -1.12740922, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.1342057 , -0.48772236,  1.01599907, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.31796351, -0.48772236,  1.56899549, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.40905582, -0.48772236,  2.11761463, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50. , 50. , 23.6, 16. , 21.5, 25.1, 18. , 19.3, 11.3, 20.2, 22.9,\n",
       "       13.8, 32. , 27.5, 12.7, 19.3,  8.1, 29.8, 12.3, 19.4, 19.1, 22.9,\n",
       "       32.5, 50. , 25. , 20.5, 21.4, 21.9,  5. , 22.8, 24.3, 13.2, 17.8,\n",
       "       18.8, 16.1, 14. , 10.2, 30.7, 23.2, 13.4, 15.4, 50. , 24.6, 21.2,\n",
       "       23.8, 17.1, 22.9, 19.9, 46. , 22. , 18.5,  8.8, 21.7, 19.2, 24.8,\n",
       "       16.6, 27.5, 14.9, 10.4, 17.6, 18.9, 20.1, 28.4,  7. , 28.7, 21.4,\n",
       "       23.9, 19.6, 16.6, 15.6, 33. ,  8.5, 19.5, 44. , 19.8, 13.9, 21.8,\n",
       "       50. , 16.2, 13.5,  9.7, 18.5, 28. , 13.8, 20.9, 21.1, 20.1, 22.3,\n",
       "       19. , 12.7, 50. ,  9.5, 32. , 15.2,  7. , 18.5, 23.3, 22. , 20.5,\n",
       "       23.1, 17.2, 15.2,  8.8, 18.3, 27.1, 18.9, 29.8, 17.5, 48.8, 23.2,\n",
       "       29.6, 42.3, 11.8, 25. ,  8.4, 22.7, 12.6, 50. ,  7.4, 20.8, 17.4,\n",
       "       31.6, 14.6, 18.5, 15.4, 31.5, 19.6, 17.8, 12.5, 23. , 20.4,  7.5,\n",
       "       17.7, 13.3, 23.7, 20. , 35.4, 50. , 13.6, 19.9, 16.2, 22.2, 33.2,\n",
       "       21. , 20.4, 23.9, 15.6, 18.7, 32.4, 18.2, 19.9, 22.6, 35.2, 24.5,\n",
       "       17.9, 29.4, 20. , 23.4, 22.2, 25. , 25.3, 29.1, 10.5, 25.2, 50. ,\n",
       "       14.1, 27. , 22.9, 10.9, 18.2, 25. , 22.2, 21.7, 17.2, 34.9, 24.6,\n",
       "       19. , 13.1, 18.6, 15.7, 24.8, 22.8, 26.6, 11. , 12. , 36.5, 37.9,\n",
       "       24.7, 23.2, 37.2, 15.3, 39.8, 21.6, 21.4, 22. , 26.4, 18.7, 33.4,\n",
       "       21.5,  8.7, 21.9, 32.2, 18.7,  7.2, 25. , 13.3, 19.1, 18.4, 26.6,\n",
       "       21.7, 13.4, 13.1, 19.1, 17.8, 19.4, 19.5, 44.8, 36. , 21.7, 13.8,\n",
       "       15.2, 18.1, 20.1, 25. , 20.6, 20.6, 22.8, 21.9, 16.3, 32.9, 20. ,\n",
       "       27.1, 27.5, 20.8, 18.9, 23.9, 36.2, 41.7, 16.8, 19.3, 14.2, 14.1,\n",
       "       19.6, 20. , 10.9, 15. , 11.7, 22.4, 24.8,  5. , 20.7, 20.6, 23. ,\n",
       "       11.5, 23.9, 19.3, 23.8, 24.2, 18.4, 20.3, 14.4, 28.7, 20.4, 18.3,\n",
       "       33.2, 20.1, 26.7, 19.6, 20.3, 20.2, 24.3, 26.4, 10.8, 16.1, 29.1,\n",
       "       38.7, 22.4, 22.2, 34.9, 19.2, 36.1, 17.4, 32.7, 19.9, 22.7, 20.6,\n",
       "       20.3, 37. , 46.7, 15.1, 20.9, 29. ,  7.2, 13.8, 33.4, 18.4, 23.8,\n",
       "       14.4, 23.7, 23. , 22.5, 23.8, 24.4, 23.1, 19.8, 41.3, 23.1, 33.3,\n",
       "       23.7, 19.4, 20.6, 33.8, 50. ,  8.4, 23.1, 30.3, 15. ,  9.6, 13.5,\n",
       "       23.3, 12.7, 14.3, 18.8])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "regression.fit(X_train,y_train) # 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7391812437637494"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702494038634443"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149004983444989"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.07581097,  1.61063367,  0.25959837, -2.30775791,  1.69404744,\n",
       "        0.23648161, -3.77044833, -1.34065246, -2.16205772,  0.49015399,\n",
       "       -4.36945302, -1.57119684,  1.57119684, -1.6243816 , -2.48591551,\n",
       "        1.54610538, -0.89998168, -0.59563619, -3.00710634,  1.69024382,\n",
       "        1.53935707,  3.83731504])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 不用sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不使用sklearn\n",
    "def model(w,b,x):\n",
    "    x = np.array(x)\n",
    "    return np.dot(x,w)+b\n",
    "\n",
    "def MSE_loss(y,y_pred,x):\n",
    "    x,y,y_pred = np.array(x),np.array(y),np.array(y_pred)\n",
    "    return np.sum((y-y_pred)**2)\n",
    "    \n",
    "# 计算梯度\n",
    "def gradient_w(x,y,y_pred):\n",
    "    x,y,y_pred = np.array(x),np.array(y),np.array(y_pred)\n",
    "    return -np.sum(np.dot(x.T,(y - y_pred)))\n",
    "\n",
    "def gradient_b(y,y_pred):\n",
    "    y,y_pred = np.array(y),np.array(y_pred)\n",
    "    return -np.sum(y - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22,) (323,)\n",
      "k = [0.48975771 0.9100363  0.56336735 0.92438901 0.74609333 0.27412262\n",
      " 0.7730738  0.23674361 0.84536881 0.35875862 0.57760223 0.65632928\n",
      " 0.90923423 0.80508023 0.55691794 0.39416892 0.1386874  0.48634289\n",
      " 0.78548982 0.67117379 0.0400182  0.34956639]  b = [2.66675173e-01 3.93409863e-01 1.49315318e-01 9.58551474e-01\n",
      " 3.43445090e-01 8.76626978e-01 7.57517705e-01 4.03356357e-01\n",
      " 3.18141831e-01 2.87461127e-01 7.24194918e-01 1.91042174e-01\n",
      " 7.44280132e-01 1.35759616e-01 8.40811997e-01 3.48549614e-01\n",
      " 6.65963655e-01 6.93070200e-01 3.19063271e-01 5.94301146e-01\n",
      " 8.28451770e-01 7.28122715e-01 8.08300353e-01 3.96933248e-01\n",
      " 5.89960288e-04 8.95706053e-02 8.64664068e-01 3.39359296e-02\n",
      " 9.04492637e-01 1.87983602e-02 1.12131226e-01 4.99464080e-01\n",
      " 5.71665023e-01 6.79826205e-01 2.05554659e-01 6.37331151e-01\n",
      " 6.17007448e-01 4.59646823e-01 4.34932336e-01 5.45110120e-01\n",
      " 9.97466989e-01 4.31519914e-01 4.50919914e-01 1.59083592e-01\n",
      " 1.10837944e-01 3.87590916e-01 6.40437509e-01 8.77148640e-01\n",
      " 3.85574367e-02 8.63069823e-01 4.15935234e-01 5.24683797e-01\n",
      " 9.19039826e-01 9.07865825e-02 9.50355649e-01 1.61743532e-01\n",
      " 6.39881175e-01 4.97362072e-01 3.21232374e-01 6.32025240e-01\n",
      " 1.13458035e-01 5.45823356e-01 4.77499808e-01 1.35411934e-01\n",
      " 9.25005259e-01 1.32185241e-01 4.88688379e-02 9.76432230e-01\n",
      " 1.66559028e-01 9.55054619e-01 7.64443373e-01 2.00159373e-01\n",
      " 9.96931673e-01 7.13428854e-01 6.47085059e-01 9.75138861e-01\n",
      " 4.88883543e-01 3.95418978e-01 1.98431531e-01 6.69356725e-01\n",
      " 8.17144934e-01 8.12245576e-01 5.56501609e-01 9.97438194e-01\n",
      " 4.60835390e-01 4.74047919e-01 1.27892635e-01 9.61996271e-01\n",
      " 7.53034477e-01 2.00627359e-01 5.58643527e-01 8.85958044e-01\n",
      " 6.00157899e-02 2.94231533e-01 8.26091069e-01 1.27354857e-01\n",
      " 2.47807610e-01 6.68168208e-01 4.78288003e-01 7.98528898e-02\n",
      " 2.87264063e-01 4.13331192e-02 7.01103990e-01 8.02478816e-01\n",
      " 2.30688313e-01 5.72391630e-01 7.35833242e-01 4.83902455e-01\n",
      " 6.44030293e-01 6.40724100e-01 3.77270378e-02 8.59049072e-01\n",
      " 8.53349275e-02 1.69129639e-01 6.33694829e-01 6.50537878e-01\n",
      " 3.14141141e-01 7.01218472e-01 9.12908883e-01 8.64743968e-01\n",
      " 1.00844947e-01 9.04811298e-01 2.23817203e-01 5.55428627e-01\n",
      " 8.88026482e-01 1.79168541e-02 4.08344573e-02 5.07424048e-01\n",
      " 8.92414911e-01 4.46038007e-01 5.10300311e-01 6.25823102e-01\n",
      " 3.42680273e-01 3.57400043e-01 7.93087060e-01 6.31926214e-01\n",
      " 9.14333012e-01 5.98162749e-01 9.89811029e-01 3.80815922e-01\n",
      " 6.31853172e-01 9.56334098e-01 6.55018257e-01 2.91415115e-01\n",
      " 1.44920405e-01 8.87981101e-01 2.62398619e-01 5.91809103e-01\n",
      " 4.93163230e-01 7.48995898e-01 8.23025395e-01 8.75994340e-01\n",
      " 8.33888054e-01 3.80295625e-01 6.33503279e-01 2.95787927e-02\n",
      " 8.44287245e-01 3.08030393e-01 2.47930043e-01 9.05809313e-01\n",
      " 4.71583782e-01 1.16775842e-01 9.71521318e-01 5.60602000e-01\n",
      " 2.56566961e-01 6.02122777e-02 2.44121496e-01 9.30911394e-01\n",
      " 4.43436230e-01 6.80080227e-01 7.80186440e-01 4.94994991e-01\n",
      " 9.63343113e-01 3.56674820e-01 5.01559425e-01 7.90369479e-01\n",
      " 2.09649166e-01 5.05462076e-01 9.67475012e-01 3.70981077e-01\n",
      " 4.69605268e-01 6.23996267e-01 4.52601792e-01 9.03747990e-01\n",
      " 7.33651791e-01 4.78000958e-01 3.70703400e-01 7.67883493e-01\n",
      " 1.26226424e-01 3.98525012e-01 7.09965758e-01 2.78716943e-01\n",
      " 9.49429182e-01 8.26121888e-01 1.49016398e-01 1.62579238e-01\n",
      " 7.19120434e-01 6.67648656e-01 7.50118332e-01 7.13977883e-02\n",
      " 5.05000241e-01 2.73951450e-01 1.61655217e-01 2.68947992e-01\n",
      " 6.73768654e-01 7.20193047e-01 1.66115994e-02 8.96761870e-01\n",
      " 2.22358382e-01 8.68795085e-01 3.79476702e-02 8.00695707e-01\n",
      " 4.78567067e-01 6.19231364e-01 3.21093822e-01 4.01743167e-01\n",
      " 5.72547897e-01 7.41662714e-01 5.71060965e-01 8.27415417e-01\n",
      " 9.38414826e-01 2.46348679e-01 1.31422881e-01 1.21011891e-01\n",
      " 1.76969728e-01 3.12802247e-01 2.86964459e-02 4.28466816e-01\n",
      " 6.62757796e-01 3.10666500e-01 4.28539770e-01 8.62053236e-01\n",
      " 1.76962227e-01 6.58811691e-02 5.28538895e-01 9.86075225e-01\n",
      " 6.25285116e-01 3.96605559e-01 2.68394193e-01 3.57831757e-01\n",
      " 8.34901569e-01 8.16881397e-01 3.86530761e-01 8.67418401e-01\n",
      " 2.33517388e-01 5.59677007e-01 3.79100790e-01 8.74791163e-01\n",
      " 7.74448163e-01 7.71281652e-01 7.74045076e-01 1.70672162e-01\n",
      " 5.55111447e-01 6.81784901e-01 5.50338208e-01 7.82172688e-01\n",
      " 7.62670344e-01 5.43087090e-01 7.14965875e-02 5.18901761e-01\n",
      " 1.17667158e-01 8.39798576e-01 7.88880470e-01 4.11796570e-02\n",
      " 4.67800550e-01 6.26489769e-01 8.84501880e-01 1.48361841e-01\n",
      " 8.20256289e-02 6.20020019e-02 1.81361523e-01 1.18454294e-01\n",
      " 6.05801462e-01 6.03391207e-01 7.39786354e-02 7.00556753e-01\n",
      " 7.11733736e-01 7.56669000e-01 6.11701325e-01 1.56282761e-01\n",
      " 7.13613916e-01 5.44131466e-01 6.24811298e-02 2.70872160e-02\n",
      " 2.25251297e-01 7.02155990e-01 4.82255761e-01 8.23837494e-01\n",
      " 7.89610538e-01 4.22878992e-01 5.72633781e-01 8.79626088e-01\n",
      " 3.05479306e-01 7.88750723e-01 9.59837164e-01 8.62185398e-01\n",
      " 5.43780700e-01 7.33223325e-01 6.09617024e-01 6.12437126e-01\n",
      " 9.74968712e-01 1.90139328e-01 9.18902731e-01 8.52642349e-01\n",
      " 5.96386466e-01 3.57212115e-01 3.10199729e-01 8.06112551e-01\n",
      " 8.95667597e-01 3.49485138e-02 9.39244395e-01 4.92918639e-01\n",
      " 8.95928416e-01 7.87094624e-01 1.20240740e-01 5.66634723e-01\n",
      " 7.25326503e-01 1.02955932e-01 8.24378937e-01 2.33371601e-01\n",
      " 5.50143643e-01 3.64818773e-01 2.03503367e-01]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# X_train.shape = (323,22)\n",
    "# y_train.shape = (323,)\n",
    "\n",
    "k,b = np.random.random((X_train.shape[1])),np.random.random((X_train.shape[0]))\n",
    "print(k.shape,b.shape)\n",
    "print('k = {}  b = {}'.format(k,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_time = 1000\n",
    "min_loss = float('inf')\n",
    "optimal_func = None\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323,)\n",
      "168084.18552628456\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(k,b,X_train)\n",
    "print(y_pred.shape)\n",
    "loss = MSE_loss(y_train,y_pred,X_train)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0次 ： loss = 168084.18552628456\n",
      "第10次 ： loss = 4.559159035387149e+17\n",
      "第20次 ： loss = 1.8063108755366115e+31\n",
      "第30次 ： loss = 7.156493014955614e+44\n",
      "第40次 ： loss = 2.8353586841962394e+58\n",
      "第50次 ： loss = 1.1233517382391972e+72\n",
      "第60次 ： loss = 4.450650758363402e+85\n",
      "第70次 ： loss = 1.7633205610176217e+99\n",
      "第80次 ： loss = 6.986168022877772e+112\n",
      "第90次 ： loss = 2.7678769659280434e+126\n",
      "第100次 ： loss = 1.0966158949265036e+140\n",
      "第110次 ： loss = 4.3447249852821765e+153\n",
      "第120次 ： loss = 1.7213534187374086e+167\n",
      "第130次 ： loss = 6.8198967765195e+180\n",
      "第140次 ： loss = 2.7020013168763565e+194\n",
      "第150次 ： loss = 1.0705163663968957e+208\n",
      "第160次 ： loss = 4.241320252384075e+221\n",
      "第170次 ： loss = 1.68038509713115e+235\n",
      "第180次 ： loss = 6.657582796472977e+248\n",
      "第190次 ： loss = 2.637693512490936e+262\n",
      "第200次 ： loss = 1.0450380083177718e+276\n",
      "第210次 ： loss = 4.140376558751261e+289\n",
      "第220次 ： loss = 1.640391824202844e+303\n",
      "第230次 ： loss = inf\n",
      "第240次 ： loss = inf\n",
      "第250次 ： loss = inf\n",
      "第260次 ： loss = inf\n",
      "第270次 ： loss = inf\n",
      "第280次 ： loss = inf\n",
      "第290次 ： loss = inf\n",
      "第300次 ： loss = inf\n",
      "第310次 ： loss = inf\n",
      "第320次 ： loss = inf\n",
      "第330次 ： loss = inf\n",
      "第340次 ： loss = inf\n",
      "第350次 ： loss = inf\n",
      "第360次 ： loss = inf\n",
      "第370次 ： loss = inf\n",
      "第380次 ： loss = inf\n",
      "第390次 ： loss = inf\n",
      "第400次 ： loss = inf\n",
      "第410次 ： loss = inf\n",
      "第420次 ： loss = inf\n",
      "第430次 ： loss = inf\n",
      "第440次 ： loss = inf\n",
      "第450次 ： loss = nan\n",
      "第460次 ： loss = nan\n",
      "第470次 ： loss = nan\n",
      "第480次 ： loss = nan\n",
      "第490次 ： loss = nan\n",
      "第500次 ： loss = nan\n",
      "第510次 ： loss = nan\n",
      "第520次 ： loss = nan\n",
      "第530次 ： loss = nan\n",
      "第540次 ： loss = nan\n",
      "第550次 ： loss = nan\n",
      "第560次 ： loss = nan\n",
      "第570次 ： loss = nan\n",
      "第580次 ： loss = nan\n",
      "第590次 ： loss = nan\n",
      "第600次 ： loss = nan\n",
      "第610次 ： loss = nan\n",
      "第620次 ： loss = nan\n",
      "第630次 ： loss = nan\n",
      "第640次 ： loss = nan\n",
      "第650次 ： loss = nan\n",
      "第660次 ： loss = nan\n",
      "第670次 ： loss = nan\n",
      "第680次 ： loss = nan\n",
      "第690次 ： loss = nan\n",
      "第700次 ： loss = nan\n",
      "第710次 ： loss = nan\n",
      "第720次 ： loss = nan\n",
      "第730次 ： loss = nan\n",
      "第740次 ： loss = nan\n",
      "第750次 ： loss = nan\n",
      "第760次 ： loss = nan\n",
      "第770次 ： loss = nan\n",
      "第780次 ： loss = nan\n",
      "第790次 ： loss = nan\n",
      "第800次 ： loss = nan\n",
      "第810次 ： loss = nan\n",
      "第820次 ： loss = nan\n",
      "第830次 ： loss = nan\n",
      "第840次 ： loss = nan\n",
      "第850次 ： loss = nan\n",
      "第860次 ： loss = nan\n",
      "第870次 ： loss = nan\n",
      "第880次 ： loss = nan\n",
      "第890次 ： loss = nan\n",
      "第900次 ： loss = nan\n",
      "第910次 ： loss = nan\n",
      "第920次 ： loss = nan\n",
      "第930次 ： loss = nan\n",
      "第940次 ： loss = nan\n",
      "第950次 ： loss = nan\n",
      "第960次 ： loss = nan\n",
      "第970次 ： loss = nan\n",
      "第980次 ： loss = nan\n",
      "第990次 ： loss = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in square\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for t in range(try_time):\n",
    "    \n",
    "    y_pred = model(k,b,X_train)\n",
    "    loss = MSE_loss(y_train,y_pred,X_train)\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_k,best_b = k,b\n",
    "    k -= learning_rate*gradient_w(X_train,y_train,y_pred)\n",
    "    b -= learning_rate*gradient_b(y_train,y_pred)\n",
    "    if t%10 == 0:\n",
    "        print('第{}次 ： loss = {}'.format((t),loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((22)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-9bcf664d7f35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# plt.scatter(X[:, 5], regression.predict(X))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   2845\u001b[0m         \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medgecolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medgecolors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2846\u001b[0m         plotnonfinite=plotnonfinite, **({\"data\": data} if data is not\n\u001b[0;32m-> 2847\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2848\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4444\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(5):\n",
    "    plt.scatter(X_train[:, 5], y[:5])\n",
    "    # plt.scatter(X[:, 5], regression.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
